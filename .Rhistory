colsample_bytree = ifelse(is.null(colsample_bytree),previusBestModel$params$colsample_bytree,colsample_bytree)
gamma = ifelse(is.null(gamma),previusBestModel$params$gamma,gamma)
reg_alpha = ifelse(is.null(reg_alpha),previusBestModel$params$reg_alpha,reg_alpha)
eta = ifelse(is.null(eta),previusBestModel$params$eta,eta)
}
clf <- xgb.train(params=list(objective="reg:linear",
booster = "gbtree",
eta=ifelse(is.null(eta),0.3,eta) ,
max_depth=ifelse(is.null(max_depth),6,max_depth) ,
subsample=ifelse(is.null(subsample),1,subsample) ,
colsample_bytree=ifelse(is.null(colsample_bytree),1,colsample_bytree) ,
min_child_weight = ifelse(is.null(min_child_weight),1,min_child_weight),
gamma = ifelse(is.null(gamma),0,gamma),
reg_alpha = ifelse(is.null(reg_alpha),0,reg_alpha)) ,
data = dtrain,
nrounds = nrounds,
verbose = 1,
seed = seed,
print_every_n=5,
early_stopping_rounds    = 10,
watchlist           = list(valid = dvalid),
maximize            = FALSE,
eval_metric='rmse'
)
modelList[[i]] <- clf
cat("Fim tunning:",i,'\n','\n')
})
}
bestScore <- 100000
bestModel <- NULL
for (i in 1:length(modelList)) {
score =modelList[[i]][["best_score"]][["valid-rmse"]]
if(score < bestScore) {
bestScore <-score;
bestModel <- modelList[[i]]
}
}
conv <- data.frame(iter=1:length(bestModel$evaluation_log$valid_rmse), valid_auc= bestModel$evaluation_log$valid_rmse)
conv <- melt(conv, id.vars = "iter")
plot <- ggplot(data = conv) + geom_line(aes(x = iter, y = value)) +
labs(x = "Nº Iteração", y = "valor da RMSE") +
theme(plot.title = element_text(hjust =  0.5))
plot
return(bestModel)
}
bestModel <- NULL
nrounds <- 10
seed <- 1
eg <- expand.grid(
max_depth = seq(3,10,2),
min_child_weight = seq(1,6,2)
)
bestModel<-xgbParameterTunning(eg,dtrain,dvalid,nrounds,seed,bestModel)
print(paste("max_depth:", bestModel$params$max_depth))
print(paste("min_child_weight:", bestModel$params$min_child_weight))
xgbParameterTunning <- function(gridOfParametersToTune,dtrain,dvalid, nrounds,seed, previusBestModel){
modelList <- NULL
for (i in 1:nrow(eg)) {
system.time({
cat("Inicio tunning:",i,'\n')
print(gridOfParametersToTune[i,])
max_depth = gridOfParametersToTune[i,"max_depth"]
min_child_weight = gridOfParametersToTune[i, "min_child_weight"]
subsample = gridOfParametersToTune[i, "subsample"]
colsample_bytree = gridOfParametersToTune[i, "colsample_bytree"]
gamma = gridOfParametersToTune[i, "gamma"]
reg_alpha = gridOfParametersToTune[i, "reg_alpha"]
eta = gridOfParametersToTune[i, "eta"]
if(!is.null(previusBestModel)){
max_depth = ifelse(is.null(max_depth),previusBestModel$params$max_depth,max_depth)
min_child_weight = ifelse(is.null(min_child_weight),previusBestModel$params$min_child_weight,min_child_weight)
subsample = ifelse(is.null(subsample),previusBestModel$params$subsample,subsample)
colsample_bytree = ifelse(is.null(colsample_bytree),previusBestModel$params$colsample_bytree,colsample_bytree)
gamma = ifelse(is.null(gamma),previusBestModel$params$gamma,gamma)
reg_alpha = ifelse(is.null(reg_alpha),previusBestModel$params$reg_alpha,reg_alpha)
eta = ifelse(is.null(eta),previusBestModel$params$eta,eta)
}
clf <- xgb.train(params=list(objective="reg:linear",
booster = "gbtree",
eta=ifelse(is.null(eta),0.3,eta) ,
max_depth=ifelse(is.null(max_depth),6,max_depth) ,
subsample=ifelse(is.null(subsample),1,subsample) ,
colsample_bytree=ifelse(is.null(colsample_bytree),1,colsample_bytree) ,
min_child_weight = ifelse(is.null(min_child_weight),1,min_child_weight),
gamma = ifelse(is.null(gamma),0,gamma),
reg_alpha = ifelse(is.null(reg_alpha),0,reg_alpha)) ,
data = dtrain,
nrounds = nrounds,
verbose = 1,
seed = seed,
print_every_n=5,
early_stopping_rounds    = 10,
watchlist           = list(valid = dvalid),
maximize            = FALSE,
eval_metric='rmse'
)
modelList[[i]] <- clf
cat("Fim tunning:",i,'\n','\n')
})
}
bestScore <- 100000
bestModel <- NULL
for (i in 1:length(modelList)) {
score =modelList[[i]][["best_score"]][["valid-rmse"]]
if(score < bestScore) {
bestScore <-score;
bestModel <- modelList[[i]]
}
}
conv <- data.frame(iter=1:length(bestModel$evaluation_log$valid_rmse), valid_auc= bestModel$evaluation_log$valid_rmse)
conv <- melt(conv, id.vars = "iter")
plot <- ggplot(data = conv) + geom_line(aes(x = iter, y = value)) +
labs(x = "Nº Iteração", y = "valor da RMSE") +
theme(plot.title = element_text(hjust =  0.5))
plot
return(bestModel)
}
bestModel <- NULL
nrounds <- 10
seed <- 1
eg <- expand.grid(
max_depth = seq(3,10,2),
min_child_weight = seq(1,6,2)
)
bestModel<-xgbParameterTunning(eg,dtrain,dvalid,nrounds,seed,bestModel)
print(paste("max_depth:", bestModel$params$max_depth))
print(paste("min_child_weight:", bestModel$params$min_child_weight))
xgbParameterTunning <- function(gridOfParametersToTune,dtrain,dvalid, nrounds,seed, previusBestModel){
modelList <- NULL
for (i in 1:nrow(eg)) {
system.time({
cat("Inicio tunning:",i,'\n')
max_depth = gridOfParametersToTune[i,"max_depth"]
min_child_weight = gridOfParametersToTune[i, "min_child_weight"]
subsample = gridOfParametersToTune[i, "subsample"]
colsample_bytree = gridOfParametersToTune[i, "colsample_bytree"]
gamma = gridOfParametersToTune[i, "gamma"]
reg_alpha = gridOfParametersToTune[i, "reg_alpha"]
eta = gridOfParametersToTune[i, "eta"]
if(!is.null(previusBestModel)){
max_depth = ifelse(is.null(max_depth),previusBestModel$params$max_depth,max_depth)
min_child_weight = ifelse(is.null(min_child_weight),previusBestModel$params$min_child_weight,min_child_weight)
subsample = ifelse(is.null(subsample),previusBestModel$params$subsample,subsample)
colsample_bytree = ifelse(is.null(colsample_bytree),previusBestModel$params$colsample_bytree,colsample_bytree)
gamma = ifelse(is.null(gamma),previusBestModel$params$gamma,gamma)
reg_alpha = ifelse(is.null(reg_alpha),previusBestModel$params$reg_alpha,reg_alpha)
eta = ifelse(is.null(eta),previusBestModel$params$eta,eta)
}
clf <- xgb.train(params=list(objective="reg:linear",
booster = "gbtree",
eta=ifelse(is.null(eta),0.3,eta) ,
max_depth=ifelse(is.null(max_depth),6,max_depth) ,
subsample=ifelse(is.null(subsample),1,subsample) ,
colsample_bytree=ifelse(is.null(colsample_bytree),1,colsample_bytree) ,
min_child_weight = ifelse(is.null(min_child_weight),1,min_child_weight),
gamma = ifelse(is.null(gamma),0,gamma),
reg_alpha = ifelse(is.null(reg_alpha),0,reg_alpha)) ,
data = dtrain,
nrounds = nrounds,
verbose = 1,
seed = seed,
print_every_n=5,
early_stopping_rounds    = 10,
watchlist           = list(valid = dvalid),
maximize            = FALSE,
eval_metric='rmse'
)
modelList[[i]] <- clf
cat("Fim tunning:",i,'\n','\n')
})
}
bestScore <- 100000
bestModel <- NULL
for (i in 1:length(modelList)) {
score =modelList[[i]][["best_score"]][["valid-rmse"]]
if(score < bestScore) {
bestScore <-score;
bestModel <- modelList[[i]]
}
}
conv <- data.frame(iter=1:length(bestModel$evaluation_log$valid_rmse), valid_auc= bestModel$evaluation_log$valid_rmse)
conv <- melt(conv, id.vars = "iter")
plot <- ggplot(data = conv) + geom_line(aes(x = iter, y = value)) +
labs(x = "Nº Iteração", y = "valor da RMSE") +
theme(plot.title = element_text(hjust =  0.5))
plot
return(bestModel)
}
bestModel <- NULL
nrounds <- 10
seed <- 1
eg <- expand.grid(
max_depth = seq(3,10,2),
min_child_weight = seq(1,6,2)
)
datatable(eg, class = 'table-bordered table-condensed')
bestModel<-xgbParameterTunning(eg,dtrain,dvalid,nrounds,seed,bestModel)
print(paste("max_depth:", bestModel$params$max_depth))
print(paste("min_child_weight:", bestModel$params$min_child_weight))
bestModel<-xgbParameterTunning(eg,dtrain,dvalid,nrounds,seed,bestModel)
xgb.plot.importance(xgb.importance(model=bestModel))
test <- fread("test_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
correctPredictionsWeek8 <- as.matrix(test[Semana==8,c("Demanda_uni_equil")])
correctPredictionsWeek9 <- as.matrix(test[Semana==9,c("Demanda_uni_equil")])
input_to_predict_week_8 = test[Semana ==8,]
input_to_predict_week_8 <- xgb.DMatrix(as.matrix(input_to_predict_week_8[, -c("Demanda_uni_equil")]),missing = NA)
pred_week_8 <- predict(bestModel,input_to_predict_week_8)
pred_week_8 <- exp(round(pred_week_8,5))-1
test <- fread("test_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
correctPredictionsWeek8 <- as.matrix(test[Semana==8,c("Demanda_uni_equil")])
correctPredictionsWeek9 <- as.matrix(test[Semana==9,c("Demanda_uni_equil")])
input_to_predict_week_8 = test[Semana ==8,]
input_to_predict_week_8 <- xgb.DMatrix(as.matrix(input_to_predict_week_8[, -c("Demanda_uni_equil")]),missing = NA)
pred_week_8 <- predict(bestModel,input_to_predict_week_8)
pred_week_8 <- exp(round(pred_week_8,5))-1
pred_week_8
test <- fread("test_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
correctPredictionsWeek8 <- as.matrix(test[Semana==8,c("Demanda_uni_equil")])
correctPredictionsWeek9 <- as.matrix(test[Semana==9,c("Demanda_uni_equil")])
input_to_predict_week_8 = test[Semana ==8,]
input_to_predict_week_8 <- xgb.DMatrix(as.matrix(input_to_predict_week_8[, -c("Demanda_uni_equil")]),missing = NA)
pred_week_8 <- predict(bestModel,input_to_predict_week_8)
pred_week_8 <- exp(round(pred_week_8,5))-1
week9_lag1_demanda <- test[Semana ==8,.(Cliente_ID,Producto_ID)]
week9_lag1_demanda$Demanda_uni_equil_lag_1 <- pred_week_8
week9_lag1_demanda <- week9_lag1_demanda[,.(Demanda_uni_equil_lag_1=mean(Demanda_uni_equil_lag_1)), by=.(Cliente_ID,Producto_ID)]
input_to_predict_week_9 <- test[Semana ==9,]
input_to_predict_week_9[, Demanda_uni_equil_lag_1 := NULL]
input_to_predict_week_9 <- merge(input_to_predict_week_9,week9_lag1_demanda,all.x=T,by=c('Cliente_ID','Producto_ID'))
setcolorder(input_to_predict_week_9, colorder)
input_to_predict_week_9 <- xgb.DMatrix(as.matrix(input_to_predict_week_9[, -c("Demanda_uni_equil")]),missing = NA)
pred_week_9 <- predict(bestModel,input_to_predict_week_9)
pred_week_9 <- exp(round(pred_week_9,5))-1
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
paste('rse:', rse(expected,predicted))
rsq <- function (x, y) cor(expected, predicted) ^ 2
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
rsq <- function (x, y) cor(expected, predicted) ^ 2
paste('rse:', rse(expected,predicted))
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
rsq <- function (x, y) cor(expected, predicted) ^ 2
rsq
paste('rse:', rse(expected,predicted))
rsq(expected,predicted)
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
rsq <- function (x, y) cor(x, y) ^ 2
rsq(predicted,expected)
paste('rse:', rse(expected,predicted))
Metrics::
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
rsq <- function (x, y) cor(x, y) ^ 2
rsq(predicted,expected)
paste('rsq:', rsq(predicted,expected))
rsq <- function(x, y) summary(lm(y~x))$r.squared
paste('rsq:', rsq(expected,predicted))
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
rsq <- function (x, y) cor(x, y) ^ 2
paste('rsq:', rsq(predicted,expected))
rsq <- function(x, y) summary(lm(y~x))$r.squared
paste('rsq:', rsq(expected,predicted))
library(dplyr)
inframe <- cbind(predicted, expected)
inframe <- data.table(predicted, expected)
inFrame <-  mutate(inFrame, resids = predicted - expected)
inframe <-  mutate(inframe, resids = predicted - expected)
ggplot(inFrame, aes(x = resids)) +
geom_histogram(binwidth = 1, fill = "white", color = "black")
ggplot(inframe, aes(x = resids)) +
geom_histogram(binwidth = 1, fill = "white", color = "black")
qqnorm(inFrame$resids)
qqnorm(inframe$resids)
qqline(inframe$resids)
ggplot(inframe, aes(x = resids)) +
geom_histogram(binwidth = 1, fill = "white", color = "black")
qqnorm(inframe$resids)
qqline(inframe$resids)
qqnorm(inframe$resids)
qqline(inframe$resids)
inframe
ggplot(inframe, aes(x=predicted), y= expected)
ggplot(inframe, aes(x=predicted), y= expected) + geom_line()
ggplot(inframe, aes(x=predicted, y= expected)) + geom_line()
qqnorm(inframe$resids)
plot(bestModel)
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
rsq <- function (x, y) cor(x, y) ^ 2
paste('rsq:', rsq(predicted,expected))
# Computando os resíduos
inframe <- data.table(predicted, expected)
inframe <-  mutate(inframe, resids = predicted - expected)
# Plotando os resíduos
ggplot(inframe, aes(x = resids)) +
geom_histogram(binwidth = 1, fill = "white", color = "black")
qqnorm(inframe$resids)
qqline(inframe$resids)
rm(input_df)
invisible(gc)
input_df <- fread("train.csv",data.table = TRUE, blank.lines.skip = TRUE,
select = c(cathegorical_vars,"Demanda_uni_equil"))
input_df <- data.table(input_df %>% dplyr::sample_frac(.001))
input_df %>% cor(method = "spearman") %>% corrplot(type = 'lower', method = 'number', tl.col = 'black', diag= F)
train <- data.table(input_df %>% dplyr::sample_frac(.7))[Semana <=7]
sid<-as.numeric(rownames(train))
test<-input_df[-sid,][Semana > 5]
rm(input_df)
invisible(gc())
train <- train[Semana > 3,]
invisible(gc())
data1<-train[,.(Semana=Semana+1,Cliente_ID,Producto_ID,Demanda_uni_equil)]
train <- merge(train,data1[Semana>6,.(Demanda_uni_equil_lag_1=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
test <- merge(test,data1[Semana>7,.(Demanda_uni_equil_lag_1=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
data1<-train[,.(Semana=Semana+2,Cliente_ID,Producto_ID,Demanda_uni_equil)]
train <- merge(train,data1[Semana>6,.(Demanda_uni_equil_lag_2=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
test <- merge(test,data1[Semana>7,.(Demanda_uni_equil_lag_2=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
data1<-train[,.(Semana=Semana+3,Cliente_ID,Producto_ID,Demanda_uni_equil)]
train <- merge(train,data1[Semana>6,.(Demanda_uni_equil_lag_3=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
test <- merge(test,data1[Semana>7,.(Demanda_uni_equil_lag_3=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
train <- train[Semana > 6]
rm(data1)
invisible(gc())
head(train)
View(train)
unlink('GitHub/DSA.Projetos-FCD-BigData.R.Azure-Projeto2/Projeto2.Otimizado.v2_cache', recursive = TRUE)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, tidyverse, highcharter, data.table, DT, skimr, gridExtra, corrplot, Matrix, xgboost, Metrics)
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, tidyverse, highcharter, data.table, DT, skimr, gridExtra, corrplot, Matrix, xgboost, Metrics)
setwd("~/GitHub/DSA.Projetos-FCD-BigData.R.Azure-Projeto2")
source("src/utils.R")
train <- fread("train_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
test <- fread("test_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
input_df <- fread("train.csv",data.table = TRUE, blank.lines.skip = TRUE,
select = c("Semana",'Cliente_ID', 'Producto_ID', 'Agencia_ID', 'Ruta_SAK', 'Demanda_uni_equil','Canal_ID'),
colClasses = c(Semana = "factor",
Agencia_ID = "factor",
Canal_ID = "factor",
Ruta_SAK = "factor",
Cliente_ID = "factor",
Producto_ID = "factor"))
train <- input_df[Semana <=7]
input_df
input_df <- fread("train.csv",data.table = TRUE, blank.lines.skip = TRUE,
select = c(cathegorical_vars,"Demanda_uni_equil"))
cathegorical_vars <- c("Semana" ,"Agencia_ID" ,"Canal_ID" ,"Ruta_SAK" ,"Cliente_ID" ,"Producto_ID" )
input_df <- fread("train.csv",data.table = TRUE, blank.lines.skip = TRUE,
select = c(cathegorical_vars,"Demanda_uni_equil"))
train <- input_df[Semana <=7]
test<-input_df[Semana > 7,]
train <- train[Semana > 3,]
data1<-train[,.(Semana=Semana+1,Cliente_ID,Producto_ID,Demanda_uni_equil)]
train <- merge(train,data1[Semana>6,.(Demanda_uni_equil_lag_1=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
test <- merge(test,data1[Semana>7,.(Demanda_uni_equil_lag_1=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
data1<-train[,.(Semana=Semana+2,Cliente_ID,Producto_ID,Demanda_uni_equil)]
train <- merge(train,data1[Semana>6,.(Demanda_uni_equil_lag_2=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
test <- merge(test,data1[Semana>7,.(Demanda_uni_equil_lag_2=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
data1<-train[,.(Semana=Semana+3,Cliente_ID,Producto_ID,Demanda_uni_equil)]
train <- merge(train,data1[Semana>6,.(Demanda_uni_equil_lag_3=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
test <- merge(test,data1[Semana>7,.(Demanda_uni_equil_lag_3=mean(Demanda_uni_equil)), by=.(Semana,Cliente_ID,Producto_ID)],all.x=T, by=c("Semana","Cliente_ID","Producto_ID"))
train <- train[Semana > 6]
head(train)
rm(data1)
invisible(gc())
rm(input_df)
invisible(gc())
for (i in 1:length(setdiff(cathegorical_vars,"Semana"))) {
print(i)
x <- setdiff(cathegorical_vars,"Semana")[i]
countVarName <- paste("avgCount",x, sep="_")
countVarNameTemp <- paste(countVarName,"temp",sep="_")
group = c(x,'Semana')
train[,(countVarNameTemp) := .N, by = group][,
(countVarName) := mean(get(countVarNameTemp),na.rm=T), by = x][
,(countVarNameTemp) := NULL]
test[,(countVarNameTemp) := .N, by = group][,
(countVarName) := mean(get(countVarNameTemp),na.rm=T), by = x][
,(countVarNameTemp) := NULL]
test <- merge(test, train[, .( trainVarCount = mean(get(countVarName))), by=group,with=TRUE] ,all.x=T, by=group)
test[is.na(trainVarCount), trainVarCount:=0]
test[is.na(get(countVarName)), (countVarName):=0]
test[,(countVarName):=trainVarCount+get(countVarName)][,trainVarCount := NULL]
}
colorder <- colnames(train)
setcolorder(test, colorder)
datatable(head(train, 100), class = 'table-bordered table-condensed')
train$Demanda_uni_equil=log(train$Demanda_uni_equil+1)
dtrain <- data.table(train %>% dplyr::sample_frac(.9))
sid<-as.numeric(rownames(dtrain)) # because rownames() returns character
dvalid<-train[-sid,]
rm(sid)
rm(train)
invisible(gc())
rm(train)
rm(test)
invisible(gc())
```{r echo=TRUE, message=TRUE, warning=FALSE, result='asis'}
train <- fread("train_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
dtrain <- data.table(train %>% dplyr::sample_frac(.8))
sid<-as.numeric(rownames(dtrain)) # because rownames() returns character
dvalid<-train[-sid,]
rm(sid)
rm(train)
invisible(gc())
#matriz de treino
dtrain <- xgb.DMatrix(as.matrix(dtrain[, -c("Demanda_uni_equil")]),
label = dtrain$Demanda_uni_equil)
#matriz de validação
dvalid <- xgb.DMatrix(as.matrix(dvalid[, -c("Demanda_uni_equil")]),
label = dvalid$Demanda_uni_equil);
clf <- xgb.train(params=list(  objective="reg:linear",
booster = "gbtree",
eta=0.1,
max_depth=10,
subsample=0.85,
colsample_bytree=0.7) ,
data = dtrain,
nrounds = 75,
verbose = 0,
seed = 23,
print_every_n=5,
early_stopping_rounds    = 10,
watchlist           = list(valid = dvalid),
maximize            = FALSE,
eval_metric='rmse'
)
clf <- xgb.train(params=list(  objective="reg:linear",
booster = "gbtree",
eta=0.1,
max_depth=10,
subsample=0.85,
colsample_bytree=0.7) ,
data = dtrain,
nrounds = 75,
verbose = 1,
seed = 23,
print_every_n=5,
early_stopping_rounds    = 10,
watchlist           = list(valid = dvalid),
maximize            = FALSE,
eval_metric='rmse'
)
bestScore <-clf[["best_score"]][["valid-rmse"]]
bestModel <- clf
print(paste("best score:",bestScore))
rm(dtrain)
rm(dvalid)
invisible(gc)
test <- fread("test_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
test$ID <- 1:nrow(test)
correctPredictionsWeek8 <- setorder(test[Semana==8,c("ID","Demanda_uni_equil")],"ID")
correctPredictionsWeek9 <- setorder(test[Semana==9,c("ID","Demanda_uni_equil")],"ID")
correctPredictionsWeek8 <- as.matrix(correctPredictionsWeek8[,c("Demanda_uni_equil")])
correctPredictionsWeek9 <- as.matrix(correctPredictionsWeek9[,c("Demanda_uni_equil")])
input_to_predict_week_8 = test[Semana ==8,]
setcolorder(input_to_predict_week_8, colorder)
setorder(input_to_predict_week_8,"ID")
input_to_predict_week_8 <- xgb.DMatrix(as.matrix(input_to_predict_week_8[, -c("ID","Demanda_uni_equil")]),missing = NA)
pred_week_8 <- predict(bestModel,input_to_predict_week_8)
pred_week_8 <- exp(round(pred_week_8,5))-1
bestScore <-clf[["best_score"]][["valid-rmse"]]
bestModel <- clf
print(paste("best score:",bestScore))
rm(dtrain)
rm(dvalid)
invisible(gc)
test <- fread("test_transformed.csv",data.table = TRUE, blank.lines.skip = TRUE)
test$ID <- 1:nrow(test)
correctPredictionsWeek8 <- setorder(test[Semana==8,c("ID","Demanda_uni_equil")],"ID")
correctPredictionsWeek9 <- setorder(test[Semana==9,c("ID","Demanda_uni_equil")],"ID")
correctPredictionsWeek8 <- as.matrix(correctPredictionsWeek8[,c("Demanda_uni_equil")])
correctPredictionsWeek9 <- as.matrix(correctPredictionsWeek9[,c("Demanda_uni_equil")])
input_to_predict_week_8 = test[Semana ==8,]
setcolorder(input_to_predict_week_8, colorder)
setorder(input_to_predict_week_8,"ID")
input_to_predict_week_8 <- xgb.DMatrix(as.matrix(input_to_predict_week_8[, -c("ID","Demanda_uni_equil")]),missing = NA)
pred_week_8 <- predict(bestModel,input_to_predict_week_8)
pred_week_8 <- exp(round(pred_week_8,5))-1
week9_lag1_demanda <- test[Semana ==8,.(ID,Cliente_ID,Producto_ID)]
week9_lag1_demanda$Demanda_uni_equil_lag_1 <- pred_week_8
week9_lag1_demanda <- week9_lag1_demanda[,.(Demanda_uni_equil_lag_1=mean(Demanda_uni_equil_lag_1)), by=.(Cliente_ID,Producto_ID)]
input_to_predict_week_9 <- test[Semana ==9,]
input_to_predict_week_9[, Demanda_uni_equil_lag_1 := NULL]
input_to_predict_week_9 <- merge(input_to_predict_week_9,week9_lag1_demanda,all.x=T,by=c('Cliente_ID','Producto_ID'))
setcolorder(input_to_predict_week_9, colorder)
setorder(input_to_predict_week_9,"ID")
input_to_predict_week_9 <- xgb.DMatrix(as.matrix(input_to_predict_week_9[, -c("ID","Demanda_uni_equil")]),missing = NA)
pred_week_9 <- predict(bestModel,input_to_predict_week_9)
pred_week_9 <- exp(round(pred_week_9,5))-1
predicted <- c(pred_week_8,pred_week_9)
expected <- c(correctPredictionsWeek8,correctPredictionsWeek9)
paste('rmsle:', rmsle(expected,predicted))
# Computando os resíduos
inframe <- data.table(predicted, expected)
inframe <-  mutate(inframe, resids = predicted - expected)
# Plotando os resíduos
qqnorm(inframe$resids)
qqline(inframe$resids)
rm(test)
invisible(gc)
